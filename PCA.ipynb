{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZEw-ZerroZ0",
        "outputId": "1348a974-1541-475e-d3e1-9167700284c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datapoint 0 =  [-0.8089016   0.8500074  -0.31285315 -0.37904612 -0.99598032]\n",
            "datapoint 1 =  [-0.52881055 -0.52441656  0.47183175 -0.00906385  0.5688507 ]\n",
            "datapoint 2 =  [-0.74698738  0.21329864 -0.06775805 -0.52573575 -0.12968164]\n",
            "datapoint 3 =  [-0.51265697 -0.23232018  0.67678738  0.31036945 -0.70310665]\n",
            "datapoint 4 =  [0.27829033 0.27474913 0.22174859 0.8600371  0.63299983]\n",
            "datapoint 5 =  [ 0.53884985 -0.82919815  0.33000546  0.4233917   0.77466837]\n",
            "datapoint 6 =  [-0.46398273 -0.51384655  0.578611   -0.24403118  0.58895895]\n",
            "datapoint 7 =  [ 0.73466206  0.59162927  0.83436183 -0.45775446  0.52170991]\n",
            "datapoint 8 =  [ 0.26082213 -0.84133535 -0.73828407 -0.39936649 -0.35543696]\n",
            "datapoint 9 =  [-0.67775702 -0.36961352  0.05105697  0.29169876  0.50129095]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(seed=1111)\n",
        "# In this code, we show how to use PCA...\n",
        "# Generate some dataset... \n",
        "\n",
        "number_of_data_points = 10\n",
        "number_of_features_per_data_point = 5\n",
        "\n",
        "# stack the data into some list\n",
        "data = np.zeros(shape=(number_of_data_points,number_of_features_per_data_point))\n",
        "for data_index in range(number_of_data_points):\n",
        "  data_point = np.random.uniform(low = -1, high = 1, size=(number_of_features_per_data_point))\n",
        "  print(\"datapoint {} = \".format(data_index),data_point)\n",
        "  data[data_index,:] = data_point"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we calculate the vector mean of the data: \n",
        "\n",
        "X_bar = np.mean(data,axis=0)\n",
        "print(\"X bar = \", X_bar)\n",
        "print(\"X bar is of size {}, which is equal to the number of features for each data point, {}\".format((X_bar.shape),number_of_features_per_data_point))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REJEkEJkuv5i",
        "outputId": "63b408f1-24d4-4b13-ae60-f5548a623063"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X bar =  [-0.19264719 -0.13810459  0.20455077 -0.01295008  0.14042731]\n",
            "X bar is of size (5,), which is equal to the number of features for each data point, 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we compute the covariance matrix of the data. The covariance matrix is of size NXN\n",
        "print(\"The covariance of the data is size {} X {}.\".format(number_of_data_points,number_of_data_points))\n",
        "# For each row in the data matrix, we subtract the datapoint vector with the mean vector X_bar and save it in a data matrix\n",
        "\n",
        "data_matrix_minus_mean = np.zeros(shape=(number_of_data_points,number_of_features_per_data_point))\n",
        "for data_index in range(number_of_data_points):\n",
        "  data_matrix_minus_mean[data_index,:] = data[data_index,:] - X_bar\n",
        "print(data_matrix_minus_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS34xzezv4fH",
        "outputId": "cd0b4c3f-5e2d-4d08-a949-5d2314910b45"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The covariance of the data is size 10 X 10.\n",
            "[[-0.61625441  0.98811199 -0.51740392 -0.36609603 -1.13640763]\n",
            " [-0.33616336 -0.38631197  0.26728098  0.00388623  0.42842338]\n",
            " [-0.55434019  0.35140323 -0.27230882 -0.51278567 -0.27010895]\n",
            " [-0.32000978 -0.0942156   0.47223661  0.32331954 -0.84353397]\n",
            " [ 0.47093752  0.41285372  0.01719782  0.87298719  0.49257252]\n",
            " [ 0.73149704 -0.69109356  0.12545469  0.43634178  0.63424106]\n",
            " [-0.27133554 -0.37574196  0.37406023 -0.23108109  0.44853164]\n",
            " [ 0.92730924  0.72973385  0.62981106 -0.44480438  0.38128259]\n",
            " [ 0.45346932 -0.70323076 -0.94283484 -0.38641641 -0.49586427]\n",
            " [-0.48510983 -0.23150893 -0.1534938   0.30464885  0.36086364]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, for each vector in data_matrix_minus_mean, we compute the outer product matrix \n",
        "matricies_list = []\n",
        "for data_index in range(number_of_data_points):\n",
        "  outer_product_matrix = np.outer(data_matrix_minus_mean[data_index,:],data_matrix_minus_mean[data_index,:])\n",
        "  matricies_list.append(outer_product_matrix)\n",
        "\n",
        "Covariance_matrix = np.array ( (1/number_of_data_points) * sum(matricies_list) )\n",
        "\n",
        "print((Covariance_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj4g6BU0yJld",
        "outputId": "228da6e5-e506-419d-de41-9de82a1765fa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.30338361 -0.03827613  0.04581511  0.04626125  0.15038302]\n",
            " [-0.03827613  0.3127845   0.01833201 -0.05515894 -0.11639392]\n",
            " [ 0.04581511  0.01833201  0.2101421   0.05035164  0.12857779]\n",
            " [ 0.04626125 -0.05515894  0.05035164  0.19474048  0.10185351]\n",
            " [ 0.15038302 -0.11639392  0.12857779  0.10185351  0.36270277]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we get the highest eigenvalues and eigenvectors to construct the PCA weights matrix\n",
        "\n",
        "number_of_reduced_features = 2\n",
        "\n",
        "eig_values, eig_vectors = np.linalg.eig(Covariance_matrix)\n",
        "print(\"eig_values = \", eig_values)\n",
        "print(\"eig_vectors = \", eig_vectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBHkJzg70ljj",
        "outputId": "f62c0be7-8366-4ff7-a020-8884c542a4b2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eig_values =  [0.61938567 0.29941861 0.22042339 0.09866559 0.14586019]\n",
            "eig_vectors =  [[ 0.46086008 -0.27907455  0.79899985 -0.23518132  0.12654789]\n",
            " [-0.35830084 -0.85388676 -0.00974319  0.35167015  0.13686158]\n",
            " [ 0.29115504 -0.42880225 -0.48070596 -0.67218984 -0.22009082]\n",
            " [ 0.29838408  0.03321243 -0.29702306  0.02377872  0.9061323 ]\n",
            " [ 0.69672389 -0.08955649 -0.20543462  0.60713528 -0.3094169 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the above eigen values and vector, we get the following W_PCA matrix\n",
        "\n",
        "W_PCA = np.zeros(shape=(number_of_reduced_features, number_of_features_per_data_point))\n",
        "\n",
        "# we pick the highest two values and their corresponding eigrn values\n",
        "W_PCA[0,:] = eig_vectors[0,:]\n",
        "W_PCA[1,:] = eig_vectors[3,:]\n",
        "\n",
        "print(\"The PCA matrix = \\n\", W_PCA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI9o0IUo1oii",
        "outputId": "9593bb33-6ed4-49e2-cb5a-76565824aa61"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The PCA matrix = \n",
            " [[ 0.46086008 -0.27907455  0.79899985 -0.23518132  0.12654789]\n",
            " [ 0.29838408  0.03321243 -0.29702306  0.02377872  0.9061323 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, for each data point, we get the reduced vector z...\n",
        "\n",
        "reduced_data = np.zeros(shape=(number_of_data_points,2))\n",
        "\n",
        "for data_index in range(number_of_data_points):\n",
        "  reduced_data[data_index,:] = np.matmul(W_PCA, data[data_index,:])\n",
        "\n",
        "print(\"The reduced matrix = \", reduced_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Sat6bE2wrQ",
        "outputId": "a444ace9-c872-430f-c624-7057a1d7ee64"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reduced matrix =  [[-0.89687015 -1.03171112]\n",
            " [ 0.35375564  0.19988776]\n",
            " [-0.35068926 -0.32568932]\n",
            " [ 0.20735478 -0.99143352]\n",
            " [ 0.10659463  0.62033022]\n",
            " [ 0.74187562  0.74724505]\n",
            " [ 0.52380357  0.20050002]\n",
            " [ 1.01379931  0.45288958]\n",
            " [-0.18594732 -0.06239956]\n",
            " [-0.17357171  0.23149938]]\n"
          ]
        }
      ]
    }
  ]
}